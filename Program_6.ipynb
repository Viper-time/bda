{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgETouZN1ion7V5G17Iumc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_mjZbPCE5bq","executionInfo":{"status":"ok","timestamp":1734111170489,"user_tz":-330,"elapsed":33692,"user":{"displayName":"Bijoy","userId":"06445704197325721984"}},"outputId":"7d4e3148-265a-4045-fa8c-19c70de5c259"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+----------+-----+------+---+-----+\n","|employee_name|department|state|salary|age|bonus|\n","+-------------+----------+-----+------+---+-----+\n","|        James|     Sales|   NY| 90000| 34|10000|\n","|      Michael|     Sales|   NV| 86000| 56|20000|\n","|       Robert|     Sales|   CA| 81000| 30|23000|\n","|        Maria|   Finance|   CA| 90000| 24|23000|\n","|        Raman|   Finance|   DE| 99000| 40|24000|\n","|        Scott|   Finance|   NY| 83000| 36|19000|\n","|          Jen|   Finance|   NY| 79000| 53|15000|\n","|         Jeff| Marketing|   NV| 80000| 25|18000|\n","|        Kumar| Marketing|   NJ| 91000| 50|21000|\n","+-------------+----------+-----+------+---+-----+\n","\n","State-wise total salaries:\n","+-----+------------+\n","|state|total_salary|\n","+-----+------------+\n","|   NV|      166000|\n","|   CA|      171000|\n","|   NY|      252000|\n","|   NJ|       91000|\n","|   DE|       99000|\n","+-----+------------+\n","\n","State-wise salaries greater than 1 lakh:\n","+-----+------------+\n","|state|total_salary|\n","+-----+------------+\n","|   NV|      166000|\n","|   CA|      171000|\n","|   NY|      252000|\n","+-----+------------+\n","\n","State-wise salaries in descending order:\n","+-----+------------+\n","|state|total_salary|\n","+-----+------------+\n","|   NY|      252000|\n","|   CA|      171000|\n","|   NV|      166000|\n","|   DE|       99000|\n","|   NJ|       91000|\n","+-----+------------+\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, sum as _sum\n","\n","# Step 1: Initialize a Spark session\n","spark = SparkSession.builder.appName(\"PySpark State-wise Salary Analysis\").getOrCreate()\n","\n","# Step 2: Define the data and schema\n","data = [\n","    (\"James\", \"Sales\", \"NY\", 90000, 34, 10000),\n","    (\"Michael\", \"Sales\", \"NV\", 86000, 56, 20000),\n","    (\"Robert\", \"Sales\", \"CA\", 81000, 30, 23000),\n","    (\"Maria\", \"Finance\", \"CA\", 90000, 24, 23000),\n","    (\"Raman\", \"Finance\", \"DE\", 99000, 40, 24000),\n","    (\"Scott\", \"Finance\", \"NY\", 83000, 36, 19000),\n","    (\"Jen\", \"Finance\", \"NY\", 79000, 53, 15000),\n","    (\"Jeff\", \"Marketing\", \"NV\", 80000, 25, 18000),\n","    (\"Kumar\", \"Marketing\", \"NJ\", 91000, 50, 21000)\n","]\n","schema = [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n","\n","# Step 3: Create an RDD from the data\n","rdd = spark.sparkContext.parallelize(data)\n","\n","# Step 4: Create a PySpark DataFrame from the RDD\n","df = rdd.toDF(schema)\n","\n","# Display the original DataFrame\n","df.show()\n","\n","# Step 5: Group by state and calculate total salaries\n","state_salary_df = df.groupBy(\"state\").agg(_sum(\"salary\").alias(\"total_salary\"))\n","\n","# Display state-wise total salaries\n","print(\"State-wise total salaries:\")\n","state_salary_df.show()\n","\n","# Step 6: Filter state-wise salaries greater than 1 lakh\n","state_salary_above_1lakh = state_salary_df.filter(col(\"total_salary\") > 100000)\n","\n","# Display state-wise salaries greater than 1 lakh\n","print(\"State-wise salaries greater than 1 lakh:\")\n","state_salary_above_1lakh.show()\n","\n","# Step 7: Sort state-wise salaries in descending order\n","state_salary_desc = state_salary_df.orderBy(col(\"total_salary\").desc())\n","\n","# Display state-wise salaries in descending order\n","print(\"State-wise salaries in descending order:\")\n","state_salary_desc.show()\n","\n","# Stop the Spark session\n","spark.stop()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"YAE859ryE9aI"},"execution_count":null,"outputs":[]}]}