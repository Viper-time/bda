{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) For a given file create a python script to test pyspark\n",
    "a) create a spark context\n",
    "b) create a RDD for any input file c, \n",
    "c) find the total count of words in the file\n",
    "d) find the word with highest occurrence\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edc8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big: 4\n",
      "Data: 5\n",
      "analysis: 2\n",
      "involves: 1\n",
      "examining: 1\n",
      "and: 12\n",
      "processing: 3\n",
      "large: 3\n",
      "complex: 1\n",
      "datasets: 3\n",
      "to: 8\n",
      "uncover: 1\n",
      "hidden: 1\n",
      "patterns,: 1\n",
      "correlations,: 1\n",
      "trends,: 1\n",
      "insights.: 2\n",
      "The: 2\n",
      "size: 1\n",
      "of: 7\n",
      "the: 3\n",
      "data,: 2\n",
      "often: 3\n",
      "too: 1\n",
      "vast: 1\n",
      "for: 6\n",
      "traditional: 1\n",
      "data-processing: 1\n",
      "software,: 1\n",
      "comes: 2\n",
      "from: 2\n",
      "various: 1\n",
      "sources: 1\n",
      "such: 1\n",
      "as: 2\n",
      "social: 1\n",
      "media,: 1\n",
      "sensors,: 1\n",
      "transaction: 1\n",
      "records,: 1\n",
      "more.: 1\n",
      ": 4\n",
      "###: 3\n",
      "Key: 1\n",
      "Concepts: 1\n",
      "Analysis:: 2\n",
      "1.: 1\n",
      "**Volume**:: 1\n",
      "Refers: 2\n",
      "massive: 2\n",
      "amounts: 2\n",
      "data: 6\n",
      "generated: 2\n",
      "daily,: 1\n",
      "measured: 1\n",
      "in: 3\n",
      "terabytes: 1\n",
      "or: 5\n",
      "petabytes.: 1\n",
      "2.: 1\n",
      "**Velocity**:: 1\n",
      "is: 2\n",
      "at: 1\n",
      "high: 1\n",
      "speed: 1\n",
      "needs: 1\n",
      "be: 1\n",
      "processed: 1\n",
      "quickly: 1\n",
      "real-time: 1\n",
      "3.: 1\n",
      "**Variety**:: 1\n",
      "multiple: 1\n",
      "formats—structured: 1\n",
      "(like: 3\n",
      "databases),: 1\n",
      "unstructured: 2\n",
      "text: 1\n",
      "video),: 1\n",
      "semi-structured: 1\n",
      "XML).: 1\n",
      "4.: 1\n",
      "**Veracity**:: 1\n",
      "quality,: 1\n",
      "accuracy,: 1\n",
      "reliability: 1\n",
      "big: 2\n",
      "include: 1\n",
      "noise: 1\n",
      "inconsistencies.: 1\n",
      "5.: 1\n",
      "**Value**:: 1\n",
      "ultimate: 1\n",
      "goal: 1\n",
      "derive: 1\n",
      "valuable: 1\n",
      "insights: 2\n",
      "that: 3\n",
      "lead: 1\n",
      "better: 2\n",
      "decision-making.: 1\n",
      "Tools: 2\n",
      "-: 9\n",
      "**Hadoop**:: 1\n",
      "A: 2\n",
      "framework: 2\n",
      "distributed: 1\n",
      "storage: 1\n",
      "across: 1\n",
      "clusters: 1\n",
      "computers.: 1\n",
      "**Spark**:: 1\n",
      "faster,: 1\n",
      "in-memory: 1\n",
      "used: 1\n",
      "large-scale: 1\n",
      "analytics.: 1\n",
      "**NoSQL: 1\n",
      "Databases**:: 1\n",
      "Databases: 1\n",
      "like: 2\n",
      "MongoDB: 1\n",
      "Cassandra: 1\n",
      "are: 1\n",
      "designed: 1\n",
      "handle: 1\n",
      "data.: 1\n",
      "**Machine: 1\n",
      "Learning**:: 1\n",
      "Algorithms: 1\n",
      "analyze: 1\n",
      "patterns: 1\n",
      "make: 1\n",
      "predictions: 1\n",
      "datasets.: 1\n",
      "**Data: 1\n",
      "Visualization: 1\n",
      "Tools**:: 1\n",
      "Tableau: 1\n",
      "Power: 1\n",
      "BI: 1\n",
      "represent: 1\n",
      "visually.: 1\n",
      "Use: 1\n",
      "Cases:: 1\n",
      "**Healthcare**:: 1\n",
      "Analyzing: 1\n",
      "patient: 1\n",
      "diagnostics: 1\n",
      "treatments.: 1\n",
      "**Finance**:: 1\n",
      "Risk: 1\n",
      "management,: 1\n",
      "fraud: 1\n",
      "detection,: 1\n",
      "customer: 1\n",
      "profiling.: 1\n",
      "**Retail**:: 1\n",
      "Personalized: 1\n",
      "recommendations: 1\n",
      "inventory: 1\n",
      "management.: 1\n",
      "**Marketing**:: 1\n",
      "Consumer: 1\n",
      "sentiment: 1\n",
      "analysis,: 1\n",
      "targeting: 1\n",
      "ads: 1\n",
      "more: 1\n",
      "effectively.: 1\n",
      "helps: 1\n",
      "organizations: 1\n",
      "turn: 1\n",
      "into: 1\n",
      "actionable: 1\n",
      "insights,: 1\n",
      "giving: 1\n",
      "them: 1\n",
      "a: 1\n",
      "competitive: 1\n",
      "edge: 1\n",
      "today’s: 1\n",
      "data-driven: 1\n",
      "world.: 1\n"
     ]
    }
   ],
   "source": [
    "# To find out path where pyspark installed\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Create SparkSession and sparkcontext\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName('Firstprogram')\\\n",
    "                    .getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "# Read the input file and Calculating words count\n",
    "text_file = sc.textFile(\"sample2 (1).txt\")\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Printing each word with its respective count\n",
    "output = counts.collect()\n",
    "for (word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f48849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Common Word: and (Count: 12)\n"
     ]
    }
   ],
   "source": [
    "# Finding the word with the highest occurrence (Question 4)\n",
    "most_common_word = counts.reduce(lambda a, b: a if a[1] > b[1] else b)\n",
    "\n",
    "# Printing the most common word and its count\n",
    "print(f\"\\nMost Common Word: {most_common_word[0]} (Count: {most_common_word[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee9aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
